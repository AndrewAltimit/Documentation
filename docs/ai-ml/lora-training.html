<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>LoRA Training Guide</title>
    <meta name="description" content="Technology and Physics notes">
    
    <link rel="stylesheet" href="/Documentation/assets/css/main.css">
    <link rel="stylesheet" href="/Documentation/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  </head>
  <body>
    <div class="site-container">
      <!-- Navigation Sidebar -->
      <nav class="navigation-sidebar">
        <div class="site-title">
          <a href="/Documentation/">Andrews Notebook</a>
        </div>
        
        
        <ul class="nav-list">
          
            <li class="nav-section">
              <h3 class="nav-section-title">Technology</h3>
              
                <ul class="nav-items">
                  
                    <li>
                      <a href="/Documentation/docs/technology/linux.html" 
                         >
                        Linux Operating System
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/docker.html" 
                         >
                        Docker Containers
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/git.html" 
                         >
                        Git Version Control
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/ssh.html" 
                         >
                        SSH
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/vim.html" 
                         >
                        Vim Text Editor
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/neovim.html" 
                         >
                        Neovim
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/tmux.html" 
                         >
                        tmux
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/terraform.html" 
                         >
                        Terraform
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/ansible.html" 
                         >
                        Ansible
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/cicd.html" 
                         >
                        CI/CD Pipelines
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/programming_languages.html" 
                         >
                        Programming Languages
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/cuda.html" 
                         >
                        CUDA Programming
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/ollama.html" 
                         >
                        Ollama
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/cloudflare.html" 
                         >
                        Cloudflare
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/vpn.html" 
                         >
                        VPN Technologies
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/container_orchestration.html" 
                         >
                        Container Orchestration
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/elasticsearch.html" 
                         >
                        Elasticsearch
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/grafana.html" 
                         >
                        Grafana
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/kafka.html" 
                         >
                        Kafka
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/computer_networking.html" 
                         >
                        Computer Networking
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/security.html" 
                         >
                        Security Best Practices
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/message_queuing.html" 
                         >
                        Message Queuing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/cryptography.html" 
                         >
                        Cryptography
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/identity_management.html" 
                         >
                        Identity Management
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/distributed_computing.html" 
                         >
                        Distributed Computing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/api_design.html" 
                         >
                        API Design
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/cloud_computing.html" 
                         >
                        Cloud Computing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/storage_technologies.html" 
                         >
                        Storage Technologies
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/websockets.html" 
                         >
                        WebSockets
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/async_programming.html" 
                         >
                        Async Programming
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/system_architecture.html" 
                         >
                        System Architecture
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/time_synchronization.html" 
                         >
                        Time Synchronization
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/big_data.html" 
                         >
                        Big Data Technologies
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/technology/sql_vs_nosql.html" 
                         >
                        SQL vs NoSQL
                      </a>
                    </li>
                  
                </ul>
              
            </li>
          
            <li class="nav-section">
              <h3 class="nav-section-title">AI/ML</h3>
              
                <ul class="nav-items">
                  
                    <li>
                      <a href="/Documentation/docs/aiml/llm_fundamentals.html" 
                         >
                        LLM Fundamentals
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/tokenization.html" 
                         >
                        Tokenization
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/transformers.html" 
                         >
                        Transformers
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/llm_finetuning.html" 
                         >
                        LLM Fine-Tuning
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/lora.html" 
                         >
                        LoRA
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/rag.html" 
                         >
                        RAG
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/embeddings.html" 
                         >
                        Embeddings
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/diffusion_models.html" 
                         >
                        Diffusion Models
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/stable_diffusion.html" 
                         >
                        Stable Diffusion
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/computer_vision.html" 
                         >
                        Computer Vision
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/cnn.html" 
                         >
                        Convolutional Neural Networks
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/rnn.html" 
                         >
                        Recurrent Neural Networks
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/gan.html" 
                         >
                        Generative Adversarial Networks
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/reinforcement_learning.html" 
                         >
                        Reinforcement Learning
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/neural_architecture_search.html" 
                         >
                        Neural Architecture Search
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/edge_ai.html" 
                         >
                        Edge AI
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/model_optimization.html" 
                         >
                        Model Optimization
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/ai_ethics.html" 
                         >
                        AI Ethics
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/explainable_ai.html" 
                         >
                        Explainable AI
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/federated_learning.html" 
                         >
                        Federated Learning
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/aiml/mlops.html" 
                         >
                        MLOps
                      </a>
                    </li>
                  
                </ul>
              
            </li>
          
            <li class="nav-section">
              <h3 class="nav-section-title">Physics</h3>
              
                <ul class="nav-items">
                  
                    <li>
                      <a href="/Documentation/docs/physics/quantum_computing.html" 
                         >
                        Quantum Computing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/superconducting_quantum_computing.html" 
                         >
                        Superconducting Quantum Computing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/topological_quantum_computing.html" 
                         >
                        Topological Quantum Computing
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/nuclear_fusion.html" 
                         >
                        Nuclear Fusion
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/plasma_physics.html" 
                         >
                        Plasma Physics
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/stellarators.html" 
                         >
                        Stellarators
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/tokamaks.html" 
                         >
                        Tokamaks
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/inertial_confinement_fusion.html" 
                         >
                        Inertial Confinement Fusion
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/magnet_technology.html" 
                         >
                        Magnet Technology
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/cryogenics.html" 
                         >
                        Cryogenics
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/vacuum_technology.html" 
                         >
                        Vacuum Technology
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/general_relativity.html" 
                         >
                        General Relativity
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/special_relativity.html" 
                         >
                        Special Relativity
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/quantum_mechanics.html" 
                         >
                        Quantum Mechanics
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/string_theory.html" 
                         >
                        String Theory
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/particle_physics.html" 
                         >
                        Particle Physics
                      </a>
                    </li>
                  
                    <li>
                      <a href="/Documentation/docs/physics/quantum_entanglement.html" 
                         >
                        Quantum Entanglement
                      </a>
                    </li>
                  
                </ul>
              
            </li>
          
        </ul>
        
      </nav>

      <!-- Main Content -->
      <main class="main-content">
        
          <header class="page-header">
            <h1>LoRA Training Guide</h1>
          </header>
        

        <article class="page-content">
          
<div class="code-example">
  <p>Learn how to train custom LoRA (Low-Rank Adaptation) models to add new styles, concepts, or characters to Stable Diffusion models.</p>
</div>

<h2 class="no_toc text-delta" id="table-of-contents">Table of contents</h2>

<ol id="markdown-toc">
  <li><a href="#what-is-lora" id="markdown-toc-what-is-lora">What is LoRA?</a>    <ol>
      <li><a href="#key-benefits" id="markdown-toc-key-benefits">Key Benefits</a></li>
      <li><a href="#how-lora-works" id="markdown-toc-how-lora-works">How LoRA Works</a></li>
    </ol>
  </li>
  <li><a href="#setup-with-ai-toolkit" id="markdown-toc-setup-with-ai-toolkit">Setup with AI Toolkit</a>    <ol>
      <li><a href="#using-docker-recommended" id="markdown-toc-using-docker-recommended">Using Docker (Recommended)</a></li>
      <li><a href="#required-hardware" id="markdown-toc-required-hardware">Required Hardware</a></li>
    </ol>
  </li>
  <li><a href="#dataset-preparation" id="markdown-toc-dataset-preparation">Dataset Preparation</a>    <ol>
      <li><a href="#image-requirements" id="markdown-toc-image-requirements">Image Requirements</a></li>
      <li><a href="#captioning-best-practices" id="markdown-toc-captioning-best-practices">Captioning Best Practices</a>        <ol>
          <li><a href="#caption-structure" id="markdown-toc-caption-structure">Caption Structure</a></li>
          <li><a href="#flux-caption-guidelines" id="markdown-toc-flux-caption-guidelines">FLUX Caption Guidelines</a></li>
        </ol>
      </li>
      <li><a href="#automated-captioning" id="markdown-toc-automated-captioning">Automated Captioning</a></li>
    </ol>
  </li>
  <li><a href="#training-configuration" id="markdown-toc-training-configuration">Training Configuration</a>    <ol>
      <li><a href="#basic-configuration-via-mcp" id="markdown-toc-basic-configuration-via-mcp">Basic Configuration via MCP</a></li>
      <li><a href="#key-parameters-explained" id="markdown-toc-key-parameters-explained">Key Parameters Explained</a>        <ol>
          <li><a href="#learning-rate" id="markdown-toc-learning-rate">Learning Rate</a></li>
          <li><a href="#steps-calculation" id="markdown-toc-steps-calculation">Steps Calculation</a></li>
          <li><a href="#rank-selection" id="markdown-toc-rank-selection">Rank Selection</a></li>
        </ol>
      </li>
      <li><a href="#advanced-configuration" id="markdown-toc-advanced-configuration">Advanced Configuration</a></li>
    </ol>
  </li>
  <li><a href="#training-process" id="markdown-toc-training-process">Training Process</a>    <ol>
      <li><a href="#starting-training" id="markdown-toc-starting-training">Starting Training</a></li>
      <li><a href="#monitoring-progress" id="markdown-toc-monitoring-progress">Monitoring Progress</a></li>
      <li><a href="#understanding-training-metrics" id="markdown-toc-understanding-training-metrics">Understanding Training Metrics</a></li>
    </ol>
  </li>
  <li><a href="#dataset-upload" id="markdown-toc-dataset-upload">Dataset Upload</a>    <ol>
      <li><a href="#direct-upload-small-datasets" id="markdown-toc-direct-upload-small-datasets">Direct Upload (Small Datasets)</a></li>
      <li><a href="#chunked-upload-large-files" id="markdown-toc-chunked-upload-large-files">Chunked Upload (Large Files)</a></li>
    </ol>
  </li>
  <li><a href="#common-training-scenarios" id="markdown-toc-common-training-scenarios">Common Training Scenarios</a>    <ol>
      <li><a href="#style-lora" id="markdown-toc-style-lora">Style LoRA</a></li>
      <li><a href="#character-lora" id="markdown-toc-character-lora">Character LoRA</a></li>
      <li><a href="#photographic-subject" id="markdown-toc-photographic-subject">Photographic Subject</a></li>
    </ol>
  </li>
  <li><a href="#optimization-techniques" id="markdown-toc-optimization-techniques">Optimization Techniques</a>    <ol>
      <li><a href="#memory-optimization" id="markdown-toc-memory-optimization">Memory Optimization</a></li>
      <li><a href="#speed-optimization" id="markdown-toc-speed-optimization">Speed Optimization</a></li>
      <li><a href="#quality-optimization" id="markdown-toc-quality-optimization">Quality Optimization</a></li>
    </ol>
  </li>
  <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>    <ol>
      <li><a href="#common-issues" id="markdown-toc-common-issues">Common Issues</a>        <ol>
          <li><a href="#overfitting" id="markdown-toc-overfitting">Overfitting</a></li>
          <li><a href="#underfitting" id="markdown-toc-underfitting">Underfitting</a></li>
          <li><a href="#style-bleeding" id="markdown-toc-style-bleeding">Style Bleeding</a></li>
        </ol>
      </li>
      <li><a href="#training-diagnostics" id="markdown-toc-training-diagnostics">Training Diagnostics</a></li>
    </ol>
  </li>
  <li><a href="#advanced-techniques" id="markdown-toc-advanced-techniques">Advanced Techniques</a>    <ol>
      <li><a href="#multi-concept-training" id="markdown-toc-multi-concept-training">Multi-Concept Training</a></li>
      <li><a href="#dreambooth-style-training" id="markdown-toc-dreambooth-style-training">DreamBooth-style Training</a></li>
      <li><a href="#progressive-training" id="markdown-toc-progressive-training">Progressive Training</a></li>
    </ol>
  </li>
  <li><a href="#using-trained-loras" id="markdown-toc-using-trained-loras">Using Trained LoRAs</a>    <ol>
      <li><a href="#in-comfyui" id="markdown-toc-in-comfyui">In ComfyUI</a></li>
      <li><a href="#combining-multiple-loras" id="markdown-toc-combining-multiple-loras">Combining Multiple LoRAs</a></li>
      <li><a href="#optimal-strength-settings" id="markdown-toc-optimal-strength-settings">Optimal Strength Settings</a></li>
    </ol>
  </li>
  <li><a href="#best-practices-summary" id="markdown-toc-best-practices-summary">Best Practices Summary</a>    <ol>
      <li><a href="#dos" id="markdown-toc-dos">Do’s</a></li>
      <li><a href="#donts" id="markdown-toc-donts">Don’ts</a></li>
    </ol>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ol>

<hr />

<h2 id="what-is-lora">What is LoRA?</h2>

<p>LoRA (Low-Rank Adaptation) is a training technique that allows you to fine-tune large models like Stable Diffusion by training only a small number of parameters. Instead of modifying the entire model, LoRA adds trainable rank decomposition matrices to existing weights.</p>

<h3 id="key-benefits">Key Benefits</h3>

<ul>
  <li><strong>Efficient</strong>: Requires 100-1000x less storage than full fine-tuning</li>
  <li><strong>Flexible</strong>: Multiple LoRAs can be combined and weighted</li>
  <li><strong>Fast</strong>: Training takes hours instead of days</li>
  <li><strong>Preserves Base Model</strong>: Original model remains unchanged</li>
</ul>

<h3 id="how-lora-works">How LoRA Works</h3>

<p>LoRA decomposes weight updates into low-rank matrices:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W' = W + ΔW = W + BA
</code></pre></div></div>

<p>Where:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">W</code> is the original weight matrix (frozen)</li>
  <li><code class="language-plaintext highlighter-rouge">B</code> and <code class="language-plaintext highlighter-rouge">A</code> are low-rank matrices (trainable)</li>
  <li>Rank <code class="language-plaintext highlighter-rouge">r &lt;&lt; d</code> (typically 4-128)</li>
</ul>

<h2 id="setup-with-ai-toolkit">Setup with AI Toolkit</h2>

<h3 id="using-docker-recommended">Using Docker (Recommended)</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Clone AI Toolkit MCP setup</span>
git clone &lt;ai-toolkit-mcp-gist-url&gt; ai-toolkit-trainer
<span class="nb">cd </span>ai-toolkit-trainer

<span class="c"># Build and start services</span>
docker-compose build
docker-compose up <span class="nt">-d</span>

<span class="c"># Access services</span>
<span class="c"># Web UI: http://localhost:8675</span>
<span class="c"># MCP API: http://localhost:8190</span>
</code></pre></div></div>

<h3 id="required-hardware">Required Hardware</h3>

<table>
  <thead>
    <tr>
      <th>Model Type</th>
      <th>Minimum VRAM</th>
      <th>Recommended VRAM</th>
      <th>Training Time (1k steps)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SD 1.5</td>
      <td>6GB</td>
      <td>8GB</td>
      <td>15-30 min</td>
    </tr>
    <tr>
      <td>SDXL</td>
      <td>12GB</td>
      <td>16GB</td>
      <td>30-60 min</td>
    </tr>
    <tr>
      <td>FLUX</td>
      <td>16GB</td>
      <td>24GB</td>
      <td>60-120 min</td>
    </tr>
  </tbody>
</table>

<h2 id="dataset-preparation">Dataset Preparation</h2>

<h3 id="image-requirements">Image Requirements</h3>

<ol>
  <li><strong>Quality Standards</strong>:
    <ul>
      <li>High resolution (512x512 minimum, 1024x1024 for FLUX/SDXL)</li>
      <li>Clear, well-lit subjects</li>
      <li>Diverse angles and contexts</li>
      <li>Consistent quality across dataset</li>
    </ul>
  </li>
  <li><strong>Dataset Size Guidelines</strong>:
    <ul>
      <li><strong>Style LoRA</strong>: 10-50 images</li>
      <li><strong>Character/Person</strong>: 20-100 images</li>
      <li><strong>Object/Concept</strong>: 15-50 images</li>
      <li><strong>Complex Style</strong>: 50-200 images</li>
    </ul>
  </li>
</ol>

<h3 id="captioning-best-practices">Captioning Best Practices</h3>

<p>Each image needs a corresponding <code class="language-plaintext highlighter-rouge">.txt</code> file with the same name:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataset/
├── image001.png
├── image001.txt
├── image002.png
├── image002.txt
└── ...
</code></pre></div></div>

<h4 id="caption-structure">Caption Structure</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[trigger_word] [subject] [details], [style], [quality], [composition]
</code></pre></div></div>

<p>Examples:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Character LoRA
xyz_person portrait of a woman, wearing a blue dress, soft lighting, professional photograph

# Style LoRA
xyz_style digital painting of a landscape, vibrant colors, fantasy art style, highly detailed

# Object LoRA
xyz_object a red sports car, studio lighting, product photography, white background
</code></pre></div></div>

<h4 id="flux-caption-guidelines">FLUX Caption Guidelines</h4>

<p>For FLUX models specifically, include these elements:</p>

<ol>
  <li><strong>Trigger Word</strong>: Always first (e.g., “xyz_style”)</li>
  <li><strong>Subject</strong>: Clear description (e.g., “a woman”, “a building”)</li>
  <li><strong>Camera Angle</strong>: Perspective (e.g., “front view”, “aerial shot”)</li>
  <li><strong>Environment</strong>: Setting (e.g., “in a forest”, “studio background”)</li>
  <li><strong>Lighting</strong>: Conditions (e.g., “golden hour”, “dramatic lighting”)</li>
</ol>

<p>Example:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xyz_style portrait of a knight, three-quarter view, in a medieval castle, torch lighting
</code></pre></div></div>

<h3 id="automated-captioning">Automated Captioning</h3>

<p>Using AI Toolkit’s caption generation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Using BLIP or WD14 taggers
</span><span class="n">responses</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">generate-captions</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/my-dataset</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">caption_model</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">blip2</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">trigger_word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_style</span><span class="sh">"</span>
    <span class="p">}</span>
<span class="p">]</span>
</code></pre></div></div>

<h2 id="training-configuration">Training Configuration</h2>

<h3 id="basic-configuration-via-mcp">Basic Configuration via MCP</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="c1"># Create training configuration
</span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">create-training-config</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">my-style-lora</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">model_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">runwayml/stable-diffusion-v1-5</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/my-style</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">resolution</span><span class="sh">"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0002</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">alpha</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">trigger_word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_style</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">test_prompts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
            <span class="sh">"</span><span class="s">xyz_style portrait of a woman</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">xyz_style landscape with mountains</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">xyz_style still life painting</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">xyz_style in a cyberpunk city at night</span><span class="sh">"</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">})</span>
</code></pre></div></div>

<h3 id="key-parameters-explained">Key Parameters Explained</h3>

<h4 id="learning-rate">Learning Rate</h4>
<ul>
  <li><strong>Default</strong>: 2e-4 (0.0002) - Good for most cases</li>
  <li><strong>Conservative</strong>: 1e-4 (0.0001) - Slower but safer</li>
  <li><strong>Aggressive</strong>: 3e-4 (0.0003) - For stubborn concepts</li>
  <li><strong>Fine-tuning</strong>: 5e-5 (0.00005) - For existing styles</li>
</ul>

<h4 id="steps-calculation">Steps Calculation</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimal Steps = 100 × number_of_images
</code></pre></div></div>

<p>Examples:</p>
<ul>
  <li>20 images → 2000 steps</li>
  <li>50 images → 5000 steps</li>
  <li>Single image → 100-500 steps</li>
</ul>

<h4 id="rank-selection">Rank Selection</h4>

<table>
  <thead>
    <tr>
      <th>Rank</th>
      <th>Use Case</th>
      <th>File Size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>4-8</td>
      <td>Simple style adjustments</td>
      <td>~10MB</td>
    </tr>
    <tr>
      <td>16-32</td>
      <td>Standard character/style LoRAs</td>
      <td>~50MB</td>
    </tr>
    <tr>
      <td>64-96</td>
      <td>Complex concepts, multiple subjects</td>
      <td>~150MB</td>
    </tr>
    <tr>
      <td>128</td>
      <td>Maximum detail/flexibility</td>
      <td>~300MB</td>
    </tr>
  </tbody>
</table>

<h3 id="advanced-configuration">Advanced Configuration</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">advanced-lora</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">model_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">ostris/Flex.1-alpha</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># FLUX model
</span>    <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/my-dataset</span><span class="sh">"</span><span class="p">,</span>
    
    <span class="c1"># Training parameters
</span>    <span class="sh">"</span><span class="s">resolution</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">gradient_accumulation_steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0002</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">lr_scheduler</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">cosine</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">lr_warmup_steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    
    <span class="c1"># LoRA parameters
</span>    <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">alpha</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">dropout</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    
    <span class="c1"># Optimization
</span>    <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">adamw</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">mixed_precision</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">fp16</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">gradient_checkpointing</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">low_vram</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    
    <span class="c1"># Regularization
</span>    <span class="sh">"</span><span class="s">prior_preservation</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">prior_loss_weight</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    
    <span class="c1"># Sampling
</span>    <span class="sh">"</span><span class="s">sample_every</span><span class="sh">"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">sample_prompts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[...],</span>
    
    <span class="c1"># Advanced
</span>    <span class="sh">"</span><span class="s">network_dim</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">network_alpha</span><span class="sh">"</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">clip_skip</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">max_token_length</span><span class="sh">"</span><span class="p">:</span> <span class="mi">225</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="training-process">Training Process</h2>

<h3 id="starting-training">Starting Training</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Start training job
</span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">start-training</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">config_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">my-style-lora</span><span class="sh">"</span>
    <span class="p">}</span>
<span class="p">})</span>

<span class="n">job_id</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()[</span><span class="sh">"</span><span class="s">result</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">job_id</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="monitoring-progress">Monitoring Progress</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check training status
</span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">get-training-status</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">job_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">job_id</span>
    <span class="p">}</span>
<span class="p">})</span>

<span class="c1"># Get training logs
</span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">get-training-logs</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">job_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">job_id</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">lines</span><span class="sh">"</span><span class="p">:</span> <span class="mi">50</span>
    <span class="p">}</span>
<span class="p">})</span>
</code></pre></div></div>

<h3 id="understanding-training-metrics">Understanding Training Metrics</h3>

<p>Key metrics to monitor:</p>
<ul>
  <li><strong>Loss</strong>: Should decrease over time (target: 0.05-0.15)</li>
  <li><strong>Learning Rate</strong>: Follows scheduler (cosine, linear, etc.)</li>
  <li><strong>Gradient Norm</strong>: Indicates training stability</li>
</ul>

<h2 id="dataset-upload">Dataset Upload</h2>

<h3 id="direct-upload-small-datasets">Direct Upload (Small Datasets)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">base64</span>

<span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">caption_path</span> <span class="ow">in</span> <span class="n">dataset_files</span><span class="p">:</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">img_content</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">()).</span><span class="nf">decode</span><span class="p">()</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">caption_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">caption</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">().</span><span class="nf">strip</span><span class="p">()</span>
    
    <span class="n">images</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
        <span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">:</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">basename</span><span class="p">(</span><span class="n">img_path</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">img_content</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">caption</span><span class="sh">"</span><span class="p">:</span> <span class="n">caption</span>
    <span class="p">})</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">upload-dataset</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">dataset_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">my-style</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">images</span><span class="sh">"</span><span class="p">:</span> <span class="n">images</span>
    <span class="p">}</span>
<span class="p">})</span>
</code></pre></div></div>

<h3 id="chunked-upload-large-files">Chunked Upload (Large Files)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># For LoRAs &gt; 100MB
</span><span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">256</span> <span class="o">*</span> <span class="mi">1024</span>  <span class="c1"># 256KB chunks
</span>
<span class="c1"># Start upload
</span><span class="n">upload_id</span> <span class="o">=</span> <span class="nf">str</span><span class="p">(</span><span class="n">uuid</span><span class="p">.</span><span class="nf">uuid4</span><span class="p">())</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">upload-lora-chunked-start</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">upload_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">upload_id</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">large_lora.safetensors</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">total_size</span><span class="sh">"</span><span class="p">:</span> <span class="n">file_size</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">metadata</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">trigger_words</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">xyz_style</span><span class="sh">"</span><span class="p">],</span>
            <span class="sh">"</span><span class="s">base_model</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">FLUX</span><span class="sh">"</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">})</span>

<span class="c1"># Upload chunks
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">file_size</span><span class="p">,</span> <span class="n">CHUNK_SIZE</span><span class="p">):</span>
    <span class="n">chunk</span> <span class="o">=</span> <span class="n">file_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">CHUNK_SIZE</span><span class="p">]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">upload-lora-chunked-append</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">upload_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">upload_id</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">chunk</span><span class="sh">"</span><span class="p">:</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">chunk</span><span class="p">).</span><span class="nf">decode</span><span class="p">(),</span>
            <span class="sh">"</span><span class="s">chunk_index</span><span class="sh">"</span><span class="p">:</span> <span class="n">i</span> <span class="o">//</span> <span class="n">CHUNK_SIZE</span>
        <span class="p">}</span>
    <span class="p">})</span>

<span class="c1"># Finalize
</span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:8190/mcp/tool</span><span class="sh">"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">tool</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">upload-lora-chunked-finish</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">arguments</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">upload_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">upload_id</span>
    <span class="p">}</span>
<span class="p">})</span>
</code></pre></div></div>

<h2 id="common-training-scenarios">Common Training Scenarios</h2>

<h3 id="style-lora">Style LoRA</h3>

<p>Training an artistic style:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">watercolor-style</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/watercolor</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">trigger_word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">wc_style</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1500</span><span class="p">,</span>  <span class="c1"># 15 images × 100
</span>    <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">test_prompts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">wc_style painting of a sunset</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">wc_style portrait of an elderly man</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">wc_style still life with flowers</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">wc_style abstract composition</span><span class="sh">"</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="character-lora">Character LoRA</h3>

<p>Training a specific character:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">game-character</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/character</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">trigger_word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_character</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3000</span><span class="p">,</span>  <span class="c1"># 30 images × 100
</span>    <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">clip_skip</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># For anime styles
</span>    <span class="sh">"</span><span class="s">test_prompts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">xyz_character standing pose, full body</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_character portrait, smiling</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_character in battle armor</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_character in casual clothes</span><span class="sh">"</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="photographic-subject">Photographic Subject</h3>

<p>Training a person or object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">product-photos</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">model_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">stabilityai/stable-diffusion-2-1</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">dataset_path</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">/ai-toolkit/datasets/product</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">trigger_word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_product</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">resolution</span><span class="sh">"</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">test_prompts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">xyz_product on white background, product photography</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_product in use, lifestyle photography</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_product close-up detail shot</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">xyz_product with natural lighting</span><span class="sh">"</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="optimization-techniques">Optimization Techniques</h2>

<h3 id="memory-optimization">Memory Optimization</h3>

<p>For limited VRAM:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="sh">"</span><span class="s">low_vram</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">gradient_checkpointing</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">gradient_accumulation_steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">mixed_precision</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">fp16</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">adafactor</span><span class="sh">"</span>  <span class="c1"># Uses less memory than AdamW
</span><span class="p">}</span>
</code></pre></div></div>

<h3 id="speed-optimization">Speed Optimization</h3>

<p>For faster training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="sh">"</span><span class="s">disable_sampling</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>  <span class="c1"># Skip sample generation
</span>    <span class="sh">"</span><span class="s">save_every</span><span class="sh">"</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>  <span class="c1"># Less frequent saves
</span>    <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">lion</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Faster convergence
</span>    <span class="sh">"</span><span class="s">lr_scheduler</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">constant</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Simple scheduler
</span>    <span class="sh">"</span><span class="s">cache_latents</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span>  <span class="c1"># Pre-compute VAE encodings
</span><span class="p">}</span>
</code></pre></div></div>

<h3 id="quality-optimization">Quality Optimization</h3>

<p>For best results:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="sh">"</span><span class="s">rank</span><span class="sh">"</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">alpha</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># Lower than rank for regularization
</span>    <span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">lr_scheduler</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">cosine_with_restarts</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">sample_every</span><span class="sh">"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">save_every</span><span class="sh">"</span><span class="p">:</span> <span class="mi">250</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">prior_preservation</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="troubleshooting">Troubleshooting</h2>

<h3 id="common-issues">Common Issues</h3>

<h4 id="overfitting">Overfitting</h4>

<p><strong>Symptoms</strong>: LoRA only generates training images
<strong>Solutions</strong>:</p>
<ul>
  <li>Reduce learning rate</li>
  <li>Decrease training steps</li>
  <li>Add dropout (0.1-0.3)</li>
  <li>Use more diverse captions</li>
  <li>Enable prior preservation</li>
</ul>

<h4 id="underfitting">Underfitting</h4>

<p><strong>Symptoms</strong>: LoRA has no effect
<strong>Solutions</strong>:</p>
<ul>
  <li>Increase learning rate</li>
  <li>Train for more steps</li>
  <li>Increase rank</li>
  <li>Check trigger word usage</li>
  <li>Verify dataset quality</li>
</ul>

<h4 id="style-bleeding">Style Bleeding</h4>

<p><strong>Symptoms</strong>: LoRA affects unintended aspects
<strong>Solutions</strong>:</p>
<ul>
  <li>Improve caption specificity</li>
  <li>Use regularization images</li>
  <li>Reduce LoRA strength when using</li>
  <li>Train with narrower focus</li>
</ul>

<h3 id="training-diagnostics">Training Diagnostics</h3>

<p>Monitor these indicators:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Good training
</span><span class="o">-</span> <span class="n">Loss</span><span class="p">:</span> <span class="n">Steadily</span> <span class="n">decreasing</span>
<span class="o">-</span> <span class="n">Sample</span> <span class="n">quality</span><span class="p">:</span> <span class="n">Improving</span> <span class="n">each</span> <span class="n">checkpoint</span>
<span class="o">-</span> <span class="n">Gradient</span> <span class="n">norm</span><span class="p">:</span> <span class="nc">Stable </span><span class="p">(</span><span class="ow">not</span> <span class="n">exploding</span><span class="p">)</span>

<span class="c1"># Problems
</span><span class="o">-</span> <span class="n">Loss</span><span class="p">:</span> <span class="n">Plateaued</span> <span class="n">early</span> <span class="err">→</span> <span class="n">Increase</span> <span class="n">learning</span> <span class="n">rate</span>
<span class="o">-</span> <span class="n">Loss</span><span class="p">:</span> <span class="n">Oscillating</span> <span class="err">→</span> <span class="n">Decrease</span> <span class="n">learning</span> <span class="n">rate</span>
<span class="o">-</span> <span class="n">Loss</span><span class="p">:</span> <span class="n">Sudden</span> <span class="n">spike</span> <span class="err">→</span> <span class="n">Check</span> <span class="k">for</span> <span class="n">corrupt</span> <span class="n">data</span>
</code></pre></div></div>

<h2 id="advanced-techniques">Advanced Techniques</h2>

<h3 id="multi-concept-training">Multi-Concept Training</h3>

<p>Train multiple concepts in one LoRA:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dataset structure
</span><span class="n">dataset</span><span class="o">/</span>
<span class="err">├──</span> <span class="n">concept1</span><span class="o">/</span>
<span class="err">│</span>   <span class="err">├──</span> <span class="n">xyz_cat_001</span><span class="p">.</span><span class="n">jpg</span>
<span class="err">│</span>   <span class="err">└──</span> <span class="n">xyz_cat_001</span><span class="p">.</span><span class="n">txt</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_cat photo of a cat...</span><span class="sh">"</span>
<span class="err">├──</span> <span class="n">concept2</span><span class="o">/</span>
<span class="err">│</span>   <span class="err">├──</span> <span class="n">xyz_dog_001</span><span class="p">.</span><span class="n">jpg</span>
<span class="err">│</span>   <span class="err">└──</span> <span class="n">xyz_dog_001</span><span class="p">.</span><span class="n">txt</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_dog photo of a dog...</span><span class="sh">"</span>
</code></pre></div></div>

<h3 id="dreambooth-style-training">DreamBooth-style Training</h3>

<p>For maximum fidelity:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="sh">"</span><span class="s">model_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">runwayml/stable-diffusion-v1-5</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">instance_prompt</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">xyz_person person</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">class_prompt</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">person</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">prior_preservation</span><span class="sh">"</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">prior_preservation_weight</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">num_class_images</span><span class="sh">"</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3000</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="progressive-training">Progressive Training</h3>

<p>Train in stages for complex concepts:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Stage 1: Basic form
</span><span class="nf">train_config</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">)</span>

<span class="c1"># Stage 2: Details
</span><span class="nf">train_config</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">resume_from</span><span class="o">=</span><span class="sh">"</span><span class="s">stage1</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Stage 3: Polish
</span><span class="nf">train_config</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.00005</span><span class="p">,</span> <span class="n">resume_from</span><span class="o">=</span><span class="sh">"</span><span class="s">stage2</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="using-trained-loras">Using Trained LoRAs</h2>

<h3 id="in-comfyui">In ComfyUI</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load in workflow
</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">LoraLoader</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">inputs</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">lora_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">my-style-lora.safetensors</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">strength_model</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">strength_clip</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.8</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="combining-multiple-loras">Combining Multiple LoRAs</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Stack LoRAs
</span><span class="p">[</span><span class="n">Base</span> <span class="n">Model</span><span class="p">]</span> <span class="err">→</span> <span class="p">[</span><span class="n">LoRA</span> <span class="mi">1</span> <span class="o">@</span> <span class="mf">0.6</span><span class="p">]</span> <span class="err">→</span> <span class="p">[</span><span class="n">LoRA</span> <span class="mi">2</span> <span class="o">@</span> <span class="mf">0.4</span><span class="p">]</span> <span class="err">→</span> <span class="p">[</span><span class="n">LoRA</span> <span class="mi">3</span> <span class="o">@</span> <span class="mf">0.3</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="optimal-strength-settings">Optimal Strength Settings</h3>

<table>
  <thead>
    <tr>
      <th>LoRA Type</th>
      <th>Model Strength</th>
      <th>CLIP Strength</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Style</td>
      <td>0.6-1.0</td>
      <td>0.6-1.0</td>
    </tr>
    <tr>
      <td>Character</td>
      <td>0.7-0.9</td>
      <td>0.7-0.9</td>
    </tr>
    <tr>
      <td>Pose</td>
      <td>0.4-0.7</td>
      <td>0.3-0.6</td>
    </tr>
    <tr>
      <td>Details</td>
      <td>0.3-0.6</td>
      <td>0.3-0.6</td>
    </tr>
  </tbody>
</table>

<h2 id="best-practices-summary">Best Practices Summary</h2>

<h3 id="dos">Do’s</h3>
<p>✓ Use unique trigger words (xyz_style, not “style”)
✓ Include trigger word in all captions
✓ Vary descriptions while maintaining consistency
✓ Test with prompts during training
✓ Save checkpoints regularly
✓ Start with conservative settings</p>

<h3 id="donts">Don’ts</h3>
<p>✗ Don’t overtrain (watch for overfitting)
✗ Don’t use copyrighted content
✗ Don’t skip dataset curation
✗ Don’t use generic trigger words
✗ Don’t ignore sampling results
✗ Don’t train at full model resolution always</p>

<h2 id="conclusion">Conclusion</h2>

<p>LoRA training opens up endless possibilities for customizing AI image generation. With proper dataset preparation, configuration tuning, and monitoring, you can create LoRAs that seamlessly integrate new concepts while maintaining the flexibility of the base model. Start with simple projects and gradually tackle more complex training scenarios as you gain experience.</p>

        </article>

        
          <aside class="toc-sidebar">
            <nav class="toc">
              <h4 class="toc-title">
                <i class="fas fa-cog"></i>
                On This Page
              </h4>
              <div class="toc-content"></div>
            </nav>
          </aside>
        
      </main>
    </div>

    <script src="/Documentation/assets/js/navigation.js"></script>
    <script>
      // Generate table of contents
      if (document.querySelector('.toc')) {
        const headings = document.querySelectorAll('.page-content h2, .page-content h3');
        const tocContent = document.querySelector('.toc-content');
        
        if (headings.length > 0) {
          const tocList = document.createElement('ul');
          tocList.className = 'toc-list';
          
          headings.forEach(heading => {
            if (!heading.id) {
              heading.id = heading.textContent.toLowerCase()
                .replace(/[^\w\s]/g, '')
                .replace(/\s+/g, '-');
            }
            
            const li = document.createElement('li');
            li.className = heading.tagName.toLowerCase();
            
            const a = document.createElement('a');
            a.href = '#' + heading.id;
            a.textContent = heading.textContent;
            
            li.appendChild(a);
            tocList.appendChild(li);
          });
          
          tocContent.appendChild(tocList);
        }
      }
    </script>
  </body>
</html>